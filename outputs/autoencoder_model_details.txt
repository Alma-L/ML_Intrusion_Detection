Autoencoder Model Architecture:
Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=18, out_features=32, bias=True)
    (1): ReLU()
    (2): Linear(in_features=32, out_features=16, bias=True)
    (3): ReLU()
    (4): Linear(in_features=16, out_features=8, bias=True)
    (5): ReLU()
  )
  (decoder): Sequential(
    (0): Linear(in_features=8, out_features=16, bias=True)
    (1): ReLU()
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=18, bias=True)
  )
)

Model State Dictionary:
encoder.0.weight: torch.Size([32, 18])
[Tensor of size (32, 18) - too large to display]
encoder.0.bias: torch.Size([32])
[Tensor of size (32,) - too large to display]
encoder.2.weight: torch.Size([16, 32])
[Tensor of size (16, 32) - too large to display]
encoder.2.bias: torch.Size([16])
[Tensor of size (16,) - too large to display]
encoder.4.weight: torch.Size([8, 16])
[Tensor of size (8, 16) - too large to display]
encoder.4.bias: torch.Size([8])
tensor([ 0.3429, -0.2382,  0.4198,  0.1591,  0.0969, -0.2302,  0.1567,  0.3041])
decoder.0.weight: torch.Size([16, 8])
[Tensor of size (16, 8) - too large to display]
decoder.0.bias: torch.Size([16])
[Tensor of size (16,) - too large to display]
decoder.2.weight: torch.Size([32, 16])
[Tensor of size (32, 16) - too large to display]
decoder.2.bias: torch.Size([32])
[Tensor of size (32,) - too large to display]
decoder.4.weight: torch.Size([18, 32])
[Tensor of size (18, 32) - too large to display]
decoder.4.bias: torch.Size([18])
[Tensor of size (18,) - too large to display]

Training Metrics:
Final Training Loss: 0.2230
Final Validation Loss: 0.2231
