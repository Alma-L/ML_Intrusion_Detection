CNN Model Architecture:
CNN(
  (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,))
  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,))
  (gpool): AdaptiveMaxPool1d(output_size=1)
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)

Model State Dictionary:
conv1.weight: torch.Size([32, 1, 3])
[Tensor of size (32, 1, 3) - too large to display]
conv1.bias: torch.Size([32])
[Tensor of size (32,) - too large to display]
conv2.weight: torch.Size([64, 32, 3])
[Tensor of size (64, 32, 3) - too large to display]
conv2.bias: torch.Size([64])
[Tensor of size (64,) - too large to display]
fc1.weight: torch.Size([32, 64])
[Tensor of size (32, 64) - too large to display]
fc1.bias: torch.Size([32])
[Tensor of size (32,) - too large to display]
fc2.weight: torch.Size([1, 32])
[Tensor of size (1, 32) - too large to display]
fc2.bias: torch.Size([1])
tensor([-0.8633])
